---
title: curl 使用入门
categories:
  - [Linux/Unix]
date: 2017-12-22 14:45:58
updated: 2017-12-22 14:45:58
tags: 
  - Curl
---
  curl 是一个命令行工具和「库」，目的是用来通过`urls`传输数据。其支持多个协议，多用来在命令行或者脚本来传输数据。通过其官方的这个入门的`Tutorial`可见其用处的广泛。
  最新版本的curl可以通过其官方网站 [curl.haxx.se](https://curl.haxx.se)获取
<!--more -->
# 简单用法
  获取Netscape网站的首页：

        curl http://www.netscape.com/
 
  获取某个FTP服务器上的README文件：
 
        curl ftp://ftp.funet.fi/README
 
  获取使用非标准端口网站的首页：
 
        curl http://www.weirdserver.com:8000/
 
  获取FTP服务器的目录列表：
 
        curl ftp://cool.haxx.se/
 
  从一个词典网站获取对curl的定义：
 
        curl dict://dict.org/m:curl
 
  同时获取两个文件：
 
        curl ftp://cool.haxx.se/ http://www.weirdserver.com:8000/
 
  获取FTPS服务器上的文件：
 
        curl ftps://files.are.secure.com/secrets.txt
 
  或者使用更适合的FTPS方式获取同样的文件：
 
        curl --ftp-ssl ftp://files.are.secure.com/secrets.txt
 
  从SSH服务器上通过SFTP获取文件：
 
        curl -u username sftp://example.com/etc/issue
 
  从SSH服务器上用SCP协议通过私钥（没有密码保护）认证获取文件：
 
        curl -u username: --key ~/.ssh/id_rsa \ 
             scp://example.com/~/file.txt

  从SSH服务器上用SCP协议通过私钥（有密码保护）认证获取文件： 
 
        curl -u username: --key ~/.ssh/id_rsa --pass private_key_password \ 
             scp://example.com/~/file.txt
 
  获取IPv6网站的首页：
 
        curl "http://[2001:1890:1112:1::20]/"
 
  从SMB服务器获取文件：

        curl -u "domain\username:passwd" smb://server.example.com/share/file.txt
 
# 下载到一个文件
 
  获取一个网页，然后保存到本地，用一个指定的名字：
 
        curl -o thatpage.html http://www.netscape.com/
 
  保存为和服务器一样的名字：
 
        curl -O http://www.netscape.com/index.html
 
  同时获取两个文件，但是保存名字不变：
 
        curl -O www.haxx.se/index.html -O curl.haxx.se/download.html
 
# 使用密码
 
## FTP
有两种方式：
 
        curl ftp://name:passwd@machine.domain:port/full/path/to/file
 
或者：
 
        curl -u name:passwd ftp://machine.domain:port/full/path/to/file
 
## FTPS
 
  和用FTP一样，但是你应该加上 SSL选项 `--ftp-ssl`。
  不建议用ftps:// 这样的方式，而建议使用：

	curl --ftp-ssl ftp://  
  这样的方式。

## SFTP / SCP
 
   和FTP使用也类似，但是你可以用 `--key`选项指定一个私钥，而不使用密码。（私钥有可能是受密码保护的，这个时候就要用`--pass`选项来指定保护私钥的密码）。
 
##  HTTP
 
  curl 也支持用户名和密码的网页，但是现在用得已经很少了。
 
        curl http://name:passwd@machige.domain/full/path/to/file
 
 或者用`-u`指定用户名和密码：
 
        curl -u name:passwd http://machine.domain/full/path/to/file
 
  HTTP支持很多不同方式的认证，curl支持其中的几种：**Basic, Digest, NTLM和Negotiate**。在没有指定方式的情况下，默认使用 **Basic**。可以通过`--anyauth`选项来让服务器选择哪一种方式。
  
   根据 URL标准，HTTP URLS不能在连接内包含用户名和密码，通过代理的时候，这就会出问题。这时候，必须使用 `-u`这样的格式来指定。 
 
## HTTPS
 
  看后面有介绍。 

# 代理
  
  curl支持HTPP和SOCKS代理服务器，即使包括认证。FTP代理也是支持的，但是现在没有一个统一的标准，大多数情况下也能工作得很好。
  从ftp服务器上通过代理的888端口获取一个文件： 
 
        curl -x my-proxy:888 ftp://ftp.leachsite.com/README
 
  用和上面一样的代理从HTTP服务器通过用户名和密码进行认证获取文件：
 
        curl -u user:passwd -x my-proxy:888 http://www.get.this/
  
  有些代理需要一些特定的认证，用`-U`选项进行指定： 
 
        curl -U user:passwd -x my-proxy:888 http://www.get.this/
 
  要指定某些域名或主机不使用认证的话可以像下面一样样`--noproxy`和逗号分割：
 
        curl --noproxy localhost,get.this -x my-proxy:888 http://www.get.this/

  如果代理是用`--proxy1.0`指定，而不是用`--proxy`或`-x`，那么curl会使用HTTP/1.0，而不是HTTP/1.1。 
  curl通过`--socks4`  `--socks5`支持 SOCKS4和SOCKS5代理。
 
  大多数FTP代理服务器被设置为在客户端看起来他们就像一个正常的FTP服务器，通过特定的命令来选择远程FTP服务器。
  curl支持`-u, -Q, --ftp-account`选项来设置通过很多ftp代理进行传输数据。举例说明，一个文件可以通过Blue Coat FTP代理传输到一个远程FTP服务器： 
 
   curl -u "Remote-FTP-Username@remote.ftp.server Proxy-Username:Remote-Pass" \ 
    --ftp-account Proxy-Password --upload-file local-file \ 
    ftp://my-ftp.proxy.server:21/remote/upload/path/

  查看你的FTP代理手册来了解哪一种形式的传输，同时用curl `-v`选项看一下到底发送出去了什么。 
 
# 范围
 
  HTTP 1.1 介绍了字节范围。通过这个，一个客户端可以请求获得某个文档的一个字节或者一部分。curl通过`-r`选项进行支持。
  
  获取文档的前100个字节：
 
        curl -r 0-99 http://www.get.this/
 
 获取文档的最后500字节：
 
        curl -r -500 http://www.get.this/
 
 curl同样支持简单的对FTP文件的范围指定。我们可以指定起止位置：
 获取开始的100字节通过FTP： 
 
        curl -r 0-99 ftp://www.get.this/README
 
# 上传
 
## FTP / FTPS / SFTP / SCP
 
 把标准输入的所有内容传输到一个服务器：
 
        curl -T - ftp://ftp.upload.com/myfile
 
 通过用户名和密码登录，把某一文件进行上传：
 
        curl -T uploadfile -u user:passwd ftp://ftp.upload.com/myfile
 
 上传一个本地文件到远程网站，文件名不变：
 
        curl -T uploadfile -u user:passwd ftp://ftp.upload.com/
 
 上传一个本地文件，并附加到某一文件：
 
        curl -T localfile -a ftp://ftp.upload.com/remotefile
 
 curl也支持通过代理上传到FTP，但这样的前提是代理设置为允许这种隧道。如果这样设置了代理的话，可以用如下类似的方式上传：
 
        curl --proxytunnel -x proxy:port -T localfile ftp.upload.com
 
## SMB / SMBS
 
        curl -T file.txt -u "domain\username:passwd"
         smb://server.example.com/share/
 
## HTTP
 
 上传标准输入到一个HTTP网站：
 
        curl -T - http://www.upload.com/myfile
> 注意：网站必须被配置为允许`put`。 
 
 对于上传HTTP数据的其他方式，查看**POST**一节。
 
# VERBOSE / DEBUG
 
  这两个选项主要用来调试用：

        curl -v ftp://ftp.upload.com/
 
  如果需要更加详细的信息，那么用`--trace 或者 --trace-ascii`选项来将信息保存到一个文件：
 
        curl --trace trace.txt www.haxx.se
 
 
# DETAILED INFORMATION

  不同协议支持不同的方式来获取指定文档的详细信息。为了让curl来展示单独一个文件的详细信息，你要用`-I/--head`选项。这将会展示单独一个文件的所有可用信息（HTTP、FTP）。HTTP信息可是非常广泛的。

  对于 HTTP，我们用`-i/--include`选项可以让头部信息在数据之前显示。curl对FTP和HTTP协议识别`-D/--dump-header`选项，然后会把头部信息存放在这个选项指定的文件内。
 
 存储HTTP头部在一个单独的文件（例子中是放在`headers.txt`中）：
 
        curl --dump-header headers.txt curl.haxx.se
 
 将头部信息存放在一个单独我文件是非常有用的，特别是当你后面要让curl使用cookies的时候。更详细的查看**cookies**一节。
 
# POST (HTTP)
 
 通过curl来POST数据非常简单的。用`-d`选项就可以了，post过去的数据会被加密。
 
 Post一个简单的"name"和"phone"顾客表：
 
        curl -d "name=Rafael%20Sagula&phone=3320780" \ 
                http://www.where.com/guest.cgi
 
 怎么样Post一个表单，请看 lesson #1:

  找出想要填写表单的所有<input>标签。（有一个叫做**formfind.pl**的perl程序可以帮助我们，curl官方网站有下载）。
 
 如果是一个”常规的“Post，使用`-d`选项。`-d`使用一个完整的"post string"，用下面这种形式：
 
        <variable1>=<data1>&<variable2>=<data2>&...
 
 'varialbe'名字是在<input>标签中的"name="后面的值，数据就是你想要填进这个input里面的值。数据**必须**是 URL encoded。也就是说，用`-`来替换空格，然后用**%XX**这样的形式来代替奇怪的符号。
 
  例子：
 
  (page located at http://www.formpost.com/getthis/
 
        <form action="post.cgi" method="post">
        <input name=user size=10>
        <input name=pass type=password size=10>
        <input name=id type=hidden value="blablabla">
        <input name=ding value="submit">
        </form>
 
  我们想输入用户名'foobar'，密码'12345'。
  想要post这两个数据，我们可以： 
 
        curl -d "user=foobar&pass=12345&id=blablabla&ding=submit"  (continues)
          http://www.formpost.com/getthis/post.cgi
 
 

  `-F`选项接受像`-F "name=contents"`这样的参数。如果想要内容来自于文件的话，用`<@filename>`替代内容。当指定一个文件的时候，同时可以指定文件内容的类型，通过附加`:type=<mime type>`在文件名字后面。当然，我们也可以把几个文件在一个字段来进行post。比如，字段**coolfiles**被用来发送三个文件，但是文件具有不同的内容类型：
 
        curl -F "coolfiles=@fil1.gif;type=image/gif,fil2.txt,fil3.html" \ 
        http://www.post.com/postit.cgi
 
 如果内容类型没有指定，curl会尝试从文件的扩展名进行猜测（只有部分能猜出来），或者用之前指定的类型（从前些个指定的文件类型），或者使用默认的**application/octet-stream**类型。
 
 仿真一下用`-F`来填充一个表单。假设我们要填充某一表单的三个字段。文件名，用户名，文件描述。我们要post我们已经写好的名字叫**cooltext.txt**的文件。现在我们用curl而不是浏览器来完成这个任务，在此之前我们必须阅读一下这个表单页面的HTML源代码来找到输入字段的名字。我们的例子里，这三个输入字段分别为：file,yourname,filedescription。
 
        curl -F "file=@cooltext.txt" -F "yourname=Daniel" \ 
             -F "filedescription=Cool text file with cool text inside" \ 
             http://www.post.com/postit.cgi
 
 如果想在一个POST请求中发送两个文件有两种方式可以做到：
 
  1. 在一个字段内指定多个文件：
 
        curl -F "pictures=@dog.gif,cat.gif"
 
  2. 在两个字端内指定两个文件：
 
        curl -F "docpicture=@dog.gif" -F "catpicture=@cat.gif"
 
 如果我们想传输字面意义的字符的时候，比如`@`,`<`,或者`;type=`的时候，用`--form-string`选项，而不是`-F`。
 
# REFERRER

  一个HTTP请求有应该包含从哪里链接到了实际的访问地址。curl可以让我们在命令行上就指定。这是非常实用的一个功能，可以用来愚弄依靠这个引用信息来返回一些信息的愚蠢的服务器或者CGI脚本。
 
        curl -e www.coolsite.com http://www.showme.com/
 
  NOTE: The Referer: [sic] field is defined in the HTTP spec to be a full URL.
 
# USER AGENT
 
 一个HTTP请求有一个选项来包含是哪个浏览器产生了这个请求。curl可以通过命令行来指定。这个你懂的。
 
 例子：
  
  curl -A 'Mozilla/3.0 (Win95; I)' http://www.nationsbank.com/
``` 
  Other common strings:
    'Mozilla/3.0 (Win95; I)'     Netscape Version 3 for Windows 95
    'Mozilla/3.04 (Win95; U)'    Netscape Version 3 for Windows 95
    'Mozilla/2.02 (OS/2; U)'     Netscape Version 2 for OS/2
    'Mozilla/4.04 [en] (X11; U; AIX 4.2; Nav)'           NS for AIX
    'Mozilla/4.05 [en] (X11; U; Linux 2.0.32 i586)'      NS for Linux
``` 
>  Note that Internet Explorer tries hard to be compatible in every way:
    'Mozilla/4.0 (compatible; MSIE 4.01; Windows 95)'    MSIE for W95
 
  Mozilla is not the only possible User-Agent name:
```
    'Konqueror/1.0'             KDE File Manager desktop client
    'Lynx/2.7.1 libwww-FM/2.14' Lynx command line browser
``` 

# COOKIES
 
  Cookies经常被服务器用来保存客户端侧的状态信息。服务器通过在头部发送一个响应行，类似`Set-Cookie: <data>`，然后内数据部分典型的包含一系列 NAME=VALUE的键值对。（用;分割）
  服务器也能指定哪个路径使用这个cookie（path-value)，什么时候过期(expire=DATE)，哪个域名使用（domain=NAME），在安全连接上是否使用（secure）。

  如果你收到了一个包含类似下面头部的页面：

        Set-Cookie: sessionid=boo123; path="/foo";
 
  这是说服务器希望在get任何一个以/foo开头的路径是要通过sessionid boo123来匹配。
 
  比如，获取一个希望名字进行匹配cookie的页面：
 
        curl -b "name=Daniel" www.sillypage.com
 
  curl同样具有使在接下来的sessions里面使用以前接受到的cookies。如果你用下面的方式保存收到的cookies：
 
        curl --dump-header headers www.example.com
 
  我们可以在马上用这个cookies来连接网站：
 
        curl -b headers www.example.com
 
 把头部信息存储到一个文件是个保存cookies的一个方式，但却不是一个方便的方式。我们可以把cookies以广为人知的`netscape cookie`格式进行保存。
 
        curl -c cookies.txt www.example.com
 
 注意，`-b`选项会启用**cookie awareness**，`-L`选项可以让curl跟随一个位置：（常常用来结合cookies使用）。因此如果一个站点发送了一个cookie和一个位置，我们就可以用一个不存在的文件来触发**cookie awareness**：
 
        curl -L -b empty.txt www.example.com
 
 用来读取cookies的文件必须是HTTP头部信息格式或者netscape格式的cookie文件，curl通过内容来判定属于哪一种格式。在上面那个代码中，curl会解析头部并且存储从www.example.com收到的cookie信息。curl在请求匹配那个位置的时候把已保存的cookie发送到服务器。`empty.txt`文件必须保证是不存在的。
 
 为了读写一个netscape的cookie文件，可以用`-b` 和`-c`选项在同一个文件上进行。
 
        curl -b cookies.txt -c cookies.txt www.example.com
 
## PROGRESS METER
 
 进度测量用来表明某些事情正在发生。不同的字段含有的意义如下：
 
  % Total    % Received % Xferd  Average Speed          Time             Curr.
                                 Dload  Upload Total    Current  Left    Speed
  0  151M    0 38608    0     0   9406      0  4:41:43  0:00:04  4:41:39  9287
 
 从左至右：
   %             - 整体完成百分比。
   Total         - 要求传输的全部大小。
   %             - 当前下载完成度
   Received      - 当前下载字节数。
   %             - 当前上传百分比
   Xferd         - 当前上传字节数。
   Average Speed
   Dload         - 平均下载速度
   Average Speed
   Upload        - 平均上传速度
   Time Total    - 预计完成时间
   Time Current  - 当前经过时间
   Time Left     - 预计剩余时间
   Curr.Speed    - 5秒内进行的平均速度。
                   
 
 `-#`选项会显示更少的解释。
 
# 速度限制
 
 Curl允许我们设置继续传输必须匹配的条件。通过`-y`和`-Y`选项，我们可以让curl在某一连续时间内速度太慢的话就退出。
 
 为了让在连续一分钟内速度低于3000b/s的时候curl中断下载，运行：
 
        curl -Y 3000 -y 60 www.far-away-site.com
 
 进行超时设置也是一个非常不错的做法，让上面这个操作必须在30分钟内完成：
 
        curl -m 1800 -Y 3000 -y 60 www.far-away-site.com
 
 强制要求curl必须不能超过一个给定的数值也是可以的，在你使用一个带宽受到限制的连接，你可能并不想让curl全部使用它。
 
 让curl每秒的传输速度不要超过10KB：
 
        curl --limit-rate 10K www.far-away-site.com
 
    or
 
        curl --limit-rate 10240 www.far-away-site.com
 
 或者不让curl上传速度超过1M/s：
 
        curl -T upload --limit-rate 1M ftp://uploadshereplease.com
 
 
# 配置文件
 
 curl在启动时，会自动读取用户目录下的`.curlrc`文件（`_curlrc`在win32系统上）。
 
 配置文件由常规命令行开关组成，但是我们也可以指定长选项来使其更具有可读性。可以把选项和参数用**空格、=、：**进行分隔。注释以*#*放在行首开始。
 
 如果在参数内包含空格，必须用双引号来包围起来`"`。在这个引用内，继续包含引用的话要用`\"`。
 
 >必须在同一行指定选项和参数。
 
 举例，设置默认超时时间和代理在一个配置文件内：
 
 我们需要超时时间是30分钟：

        -m 1800

 ... 对所有的访问使用同一代理：

        proxy = proxy.our.domain.com:8080
 
 行尾的空白符是重要的，但是所有行首字母前的空格都会被忽略。
 
 有时候我们又不想让curl来读取默认的配置文件，那么可以将`-q`作为第一各选项：
 
        curl -q www.thatsite.com
 
 在curl没有URL的时候，可以从个本地帮助页面获取并显示，可以这样进行配置：
  Force curl to get and display a local help page in case it is invoked
  without URL by making a config file similar to:
 
 默认获取地址：

        url = "http://help.with.curl.com/curlhelp.html"
 
 我们还可以通过`-K/--config`选项指定另外一个配置文件。如果我们把配置文件命名成`-`的话，curl就会从标准输入读入配置，当你想要在配置文件内隐藏某些东西的时候这是非常不错的办法：
 
        echo "user = user:passwd" | curl -K - http://that.secret.site.com
 
# 额外头部
 
 在自定义的程序里面的时候可能会需要传输一些自己定义的头部信息。这时候我们就可以使用 `-H`标志。
 
 比如，在获取一个页面的时候，发送头部"X-you-and-me: yes"：
 
        curl -H "X-you-and-me: yes" www.love.com
 
 假入我们想让curl发送一个与正常情况不同的文本也是很实用的。`-H header`代替了curl在正常情况下要发送的信息。如果用空的来替代一个内部headr，就组织了这个头部信息的发送。我们想要阻止`Host:`头部被发送的话：
 
        curl -H "Host:" www.server.com
 
# FTP and PATH NAMES
 
 要注意到当我们在用`ftp://URL`来获取文件的时候，后面的路径是相对于进入目录的。为了获取`README`文件，我们这样：
 
        curl ftp://user:passwd@my.site.com/README
 
 但是如果我们想从根目录里面获取同样名字的文件的话，使用：
 
        curl ftp://user:passwd@my.site.com//README
 
 在文件名前面加上一个斜线。
 
# SFTP and SCP and PATH NAMES
 
 对于`sftp:`和`scp:`的地址标识，给出的路径名应该是绝对路径名。如果想要获取远程机器用户目录下的一个文件，像下面这样：
 
        curl -u $USER sftp://home.example.com/~/.bashrc
 
# FTP and firewalls
 
 FTP协议需要参与连接的一端在传输数据之前打开一个新的连接。有两个方式可以达成。
 
 curl默认的方式叫做**`PASV`**，这会让服务器来打开一个端口，让客户端来进行连接。在客户端在防火墙后的时候，这是非常实用的。
 
        curl ftp.download.com
 
 如果是服务器在防火墙后面，被封禁了除21外其他所有端口的时候（或者只支持PASV命令），另外一种方式就是使用`PORT`命令让服务器来连接到给定的客户端了ip好端口。（和PORT命令类似）
 
 `-P`标志让curl支持一些不同的选项。我们的机器可能会拥有几个ip或者几个网卡，可以让curl来选择使用哪一个。默认的可以这样使用：
 
        curl -P - ftp.download.com
 
 用PORT模式下载，但是使用'le0'网卡的IP地址（这种方式在windows下并不能工作）：
 
        curl -P le0 ftp.download.com
 
 用PORT模式下载，但是用192.168.0.10作为我们的IP地址：
 
        curl -P 192.168.0.10 ftp.download.com
 
# NETWORK INTERFACE（网络接口）
 
 从指定的接口接收一个网页：
 
        curl --interface eth0:1 http://www.netscape.com/
 
  or
 
        curl --interface 192.168.1.10 http://www.netscape.com/
 
## HTTPS

  安全HTTP要求在编译的时候安装SSL库。如果支持，curl就可以用过 https协议收发数据或文档。
 
  比如：
 
        curl https://www.secure-site.com
   
   Curl也支持使用合法的个人证书来 **get/post** 文件。唯一的缺点就是证书格式必须是`PEM`的。**PEM**是一个标准的、开放的存储证书的格式，但是并不并大多数浏览器所使用（Netscape和MSIE都使用的是PKCS#12）。如果你想让curl使用你在其他浏览器上已经使用的证书，那么你就得下载一个转换器来将它转换成**PEM**格式。这种工具在最近的OPENSSL工具里面已经包含了，老版本的话，有一个叫做SSLeay的工具可以使用。
 
   下面是怎么样使用一个含有密码的证书来获取网站数据：

 
        curl -E /path/to/cert.pem:password https://secure.site.com/
 
  If you neglect to specify the password on the command line, you will be
  prompted for the correct password before any data can be received.
 
  Many older SSL-servers have problems with SSLv3 or TLS, which newer versions
  of OpenSSL etc use, therefore it is sometimes useful to specify what
  SSL-version curl should use. Use -3, -2 or -1 to specify that exact SSL
  version to use (for SSLv3, SSLv2 or TLSv1 respectively):
 
        curl -2 https://secure.site.com/
 
  Otherwise, curl will first attempt to use v3 and then v2.
 
  To use OpenSSL to convert your favourite browser's certificate into a PEM
  formatted one that curl can use, do something like this:
 
    In Netscape, you start with hitting the 'Security' menu button.
 
    Select 'certificates->yours' and then pick a certificate in the list
 
    Press the 'Export' button
 
    enter your PIN code for the certs
 
    select a proper place to save it
 
    Run the 'openssl' application to convert the certificate. If you cd to the
    openssl installation, you can do it like:
 
# ./apps/openssl pkcs12 -in [file you saved] -clcerts -out [PEMfile]
 
    In Firefox, select Options, then Advanced, then the Encryption tab,
    View Certificates. This opens the Certificate Manager, where you can
    Export. Be sure to select PEM for the Save as type.
 
    In Internet Explorer, select Internet Options, then the Content tab, then
    Certificates. Then you can Export, and depending on the format you may
    need to convert to PEM.
 
    In Chrome, select Settings, then Show Advanced Settings. Under HTTPS/SSL
    select Manage Certificates.
 
RESUMING FILE TRANSFERS
 
 To continue a file transfer where it was previously aborted, curl supports
 resume on HTTP(S) downloads as well as FTP uploads and downloads.
 
 Continue downloading a document:
 
        curl -C - -o file ftp://ftp.server.com/path/file
 
 Continue uploading a document(*1):
 
        curl -C - -T file ftp://ftp.server.com/path/file
 
 Continue downloading a document from a web server(*2):
 
        curl -C - -o file http://www.server.com/
 
 (*1) = This requires that the FTP server supports the non-standard command
        SIZE. If it doesn't, curl will say so.
 
 (*2) = This requires that the web server supports at least HTTP/1.1. If it
        doesn't, curl will say so.
 
TIME CONDITIONS
 
 HTTP allows a client to specify a time condition for the document it
 requests. It is If-Modified-Since or If-Unmodified-Since. Curl allows you to
 specify them with the -z/--time-cond flag.
 
 For example, you can easily make a download that only gets performed if the
 remote file is newer than a local copy. It would be made like:
 
        curl -z local.html http://remote.server.com/remote.html
 
 Or you can download a file only if the local file is newer than the remote
 one. Do this by prepending the date string with a '-', as in:
 
        curl -z -local.html http://remote.server.com/remote.html
 
 You can specify a "free text" date as condition. Tell curl to only download
 the file if it was updated since January 12, 2012:
 
        curl -z "Jan 12 2012" http://remote.server.com/remote.html
 
 Curl will then accept a wide range of date formats. You always make the date
 check the other way around by prepending it with a dash '-'.
 
DICT
 
  For fun try
 
        curl dict://dict.org/m:curl
        curl dict://dict.org/d:heisenbug:jargon
        curl dict://dict.org/d:daniel:web1913
 
  Aliases for 'm' are 'match' and 'find', and aliases for 'd' are 'define'
  and 'lookup'. For example,
 
        curl dict://dict.org/find:curl
 
  Commands that break the URL description of the RFC (but not the DICT
  protocol) are
 
        curl dict://dict.org/show:db
        curl dict://dict.org/show:strat
 
  Authentication is still missing (but this is not required by the RFC)
 
LDAP
 
  If you have installed the OpenLDAP library, curl can take advantage of it
  and offer ldap:// support.
  On Windows, curl will use WinLDAP from Platform SDK by default.
 
  Default protocol version used by curl is LDAPv3. LDAPv2 will be used as
  fallback mechanism in case if LDAPv3 will fail to connect.
 
  LDAP is a complex thing and writing an LDAP query is not an easy task. I do
  advise you to dig up the syntax description for that elsewhere. One such
  place might be:
 
  RFC 2255, "The LDAP URL Format" https://curl.haxx.se/rfc/rfc2255.txt
 
  To show you an example, this is how I can get all people from my local LDAP
  server that has a certain sub-domain in their email address:
 
        curl -B "ldap://ldap.frontec.se/o=frontec??sub?mail=*sth.frontec.se"
 
  If I want the same info in HTML format, I can get it by not using the -B
  (enforce ASCII) flag.
 
  You also can use authentication when accessing LDAP catalog:
 
      curl -u user:passwd "ldap://ldap.frontec.se/o=frontec??sub?mail=*"
      curl "ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*"
 
  By default, if user and password provided, OpenLDAP/WinLDAP will use basic
  authentication. On Windows you can control this behavior by providing
  one of --basic, --ntlm or --digest option in curl command line
 
      curl --ntlm "ldap://user:passwd@ldap.frontec.se/o=frontec??sub?mail=*"
 
  On Windows, if no user/password specified, auto-negotiation mechanism will
  be used with current logon credentials (SSPI/SPNEGO).
 
ENVIRONMENT VARIABLES
 
  Curl reads and understands the following environment variables:
 
        http_proxy, HTTPS_PROXY, FTP_PROXY
 
  They should be set for protocol-specific proxies. General proxy should be
  set with
 
        ALL_PROXY
 
  A comma-separated list of host names that shouldn't go through any proxy is
  set in (only an asterisk, '*' matches all hosts)
 
        NO_PROXY
 
  If the host name matches one of these strings, or the host is within the
  domain of one of these strings, transactions with that node will not be
  proxied. When a domain is used, it needs to start with a period. A user can
  specify that both www.example.com and foo.example.com should not uses a
  proxy by setting NO_PROXY to ".example.com". By including the full name you
  can exclude specific host names, so to make www.example.com not use a proxy
  but still have foo.example.com do it, set NO_PROXY to "www.example.com"
 
  The usage of the -x/--proxy flag overrides the environment variables.
 
NETRC
 
  Unix introduced the .netrc concept a long time ago. It is a way for a user
  to specify name and password for commonly visited FTP sites in a file so
  that you don't have to type them in each time you visit those sites. You
  realize this is a big security risk if someone else gets hold of your
  passwords, so therefore most unix programs won't read this file unless it is
  only readable by yourself (curl doesn't care though).
 
  Curl supports .netrc files if told to (using the -n/--netrc and
  --netrc-optional options). This is not restricted to just FTP,
  so curl can use it for all protocols where authentication is used.
 
  A very simple .netrc file could look something like:
 
        machine curl.haxx.se login iamdaniel password mysecret
 
CUSTOM OUTPUT
 
  To better allow script programmers to get to know about the progress of
  curl, the -w/--write-out option was introduced. Using this, you can specify
  what information from the previous transfer you want to extract.
 
  To display the amount of bytes downloaded together with some text and an
  ending newline:
 
        curl -w 'We downloaded %{size_download} bytes\n' www.download.com
 
KERBEROS FTP TRANSFER
 
  Curl supports kerberos4 and kerberos5/GSSAPI for FTP transfers. You need
  the kerberos package installed and used at curl build time for it to be
  available.
 
  First, get the krb-ticket the normal way, like with the kinit/kauth tool.
  Then use curl in way similar to:
 
        curl --krb private ftp://krb4site.com -u username:fakepwd
 
  There's no use for a password on the -u switch, but a blank one will make
  curl ask for one and you already entered the real password to kinit/kauth.
 
TELNET
 
  The curl telnet support is basic and very easy to use. Curl passes all data
  passed to it on stdin to the remote server. Connect to a remote telnet
  server using a command line similar to:
 
        curl telnet://remote.server.com
 
  And enter the data to pass to the server on stdin. The result will be sent
  to stdout or to the file you specify with -o.
 
  You might want the -N/--no-buffer option to switch off the buffered output
  for slow connections or similar.
 
  Pass options to the telnet protocol negotiation, by using the -t option. To
  tell the server we use a vt100 terminal, try something like:
 
        curl -tTTYPE=vt100 telnet://remote.server.com
 
  Other interesting options for it -t include:
 
   - XDISPLOC=<X display> Sets the X display location.
 
   - NEW_ENV=<var,val> Sets an environment variable.
 
  NOTE: The telnet protocol does not specify any way to login with a specified
  user and password so curl can't do that automatically. To do that, you need
  to track when the login prompt is received and send the username and
  password accordingly.
 
PERSISTENT CONNECTIONS
 
  Specifying multiple files on a single command line will make curl transfer
  all of them, one after the other in the specified order.
 
  libcurl will attempt to use persistent connections for the transfers so that
  the second transfer to the same host can use the same connection that was
  already initiated and was left open in the previous transfer. This greatly
  decreases connection time for all but the first transfer and it makes a far
  better use of the network.
 
  Note that curl cannot use persistent connections for transfers that are used
  in subsequence curl invokes. Try to stuff as many URLs as possible on the
  same command line if they are using the same host, as that'll make the
  transfers faster. If you use an HTTP proxy for file transfers, practically
  all transfers will be persistent.
 
MULTIPLE TRANSFERS WITH A SINGLE COMMAND LINE
 
  As is mentioned above, you can download multiple files with one command line
  by simply adding more URLs. If you want those to get saved to a local file
  instead of just printed to stdout, you need to add one save option for each
  URL you specify. Note that this also goes for the -O option (but not
  --remote-name-all).
 
  For example: get two files and use -O for the first and a custom file
  name for the second:
 
    curl -O http://url.com/file.txt ftp://ftp.com/moo.exe -o moo.jpg
 
  You can also upload multiple files in a similar fashion:
 
    curl -T local1 ftp://ftp.com/moo.exe -T local2 ftp://ftp.com/moo2.txt
 
IPv6
 
  curl will connect to a server with IPv6 when a host lookup returns an IPv6
  address and fall back to IPv4 if the connection fails. The --ipv4 and --ipv6
  options can specify which address to use when both are available. IPv6
  addresses can also be specified directly in URLs using the syntax:
 
    http://[2001:1890:1112:1::20]/overview.html
 
  When this style is used, the -g option must be given to stop curl from
  interpreting the square brackets as special globbing characters.  Link local
  and site local addresses including a scope identifier, such as fe80::1234%1,
  may also be used, but the scope portion must be numeric or match an existing
  network interface on Linux and the percent character must be URL escaped. The
  previous example in an SFTP URL might look like:
 
    sftp://[fe80::1234%251]/
 
  IPv6 addresses provided other than in URLs (e.g. to the --proxy, --interface
  or --ftp-port options) should not be URL encoded.
 
METALINK
 
  Curl supports Metalink (both version 3 and 4 (RFC 5854) are supported), a way
  to list multiple URIs and hashes for a file. Curl will make use of the mirrors
  listed within for failover if there are errors (such as the file or server not
  being available). It will also verify the hash of the file after the download
  completes. The Metalink file itself is downloaded and processed in memory and
  not stored in the local file system.
 
  Example to use a remote Metalink file:
 
    curl --metalink http://www.example.com/example.metalink
 
  To use a Metalink file in the local file system, use FILE protocol (file://):
 
    curl --metalink file://example.metalink
 
  Please note that if FILE protocol is disabled, there is no way to use a local
  Metalink file at the time of this writing. Also note that if --metalink and
  --include are used together, --include will be ignored. This is because including
  headers in the response will break Metalink parser and if the headers are included
  in the file described in Metalink file, hash check will fail.
 
MAILING LISTS
 
  For your convenience, we have several open mailing lists to discuss curl,
  its development and things relevant to this. Get all info at
  https://curl.haxx.se/mail/. Some of the lists available are:
 
  curl-users
 
    Users of the command line tool. How to use it, what doesn't work, new
    features, related tools, questions, news, installations, compilations,
    running, porting etc.
 
  curl-library
 
    Developers using or developing libcurl. Bugs, extensions, improvements.
 
  curl-announce
 
    Low-traffic. Only receives announcements of new public versions. At worst,
    that makes something like one or two mails per month, but usually only one
    mail every second month.
 
  curl-and-php
 
    Using the curl functions in PHP. Everything curl with a PHP angle. Or PHP
    with a curl angle.
 
  curl-and-python
 
    Python hackers using curl with or without the python binding pycurl.
 
  Please direct curl questions, feature requests and trouble reports to one of
  these mailing lists instead of mailing any individual.
